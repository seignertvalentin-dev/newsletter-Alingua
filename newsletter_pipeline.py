#!/usr/bin/env python3
"""
NEWSLETTER GENERATOR - PIPELINE COMPLET
G√©n√®re automatiquement une newsletter quotidienne en allemand niveau A2

Pipeline:
1. R√©cup√©ration des flux RSS
2. Scoring et s√©lection du meilleur article
3. Extraction du contenu
4. Simplification avec LLM (Phi-3)
5. G√©n√©ration HTML

Usage: python3 newsletter_pipeline.py
"""

import requests
from bs4 import BeautifulSoup
import feedparser
import warnings
import json
import re
import ssl
from datetime import datetime

warnings.filterwarnings('ignore', message='Unverified HTTPS request')

# ============================================================================
# CONFIGURATION
# ============================================================================

FLUX_RSS = [
    {
        "nom": "DW Culture",
        "url": "https://rss.dw.com/rdf/rss-de-cul",
        "score_base": 2
    },
    {
        "nom": "Tagesschau",
        "url": "https://www.tagesschau.de/xml/rss2",
        "score_base": 1
    }
]

MOTS_CLES_POSITIFS = [
    "kultur", "gesellschaft", "geschichte", "umwelt", "europa",
    "kunst", "musik", "film", "literatur", "wissenschaft"
]

MOTS_CLES_NEGATIFS = [
    "tote", "krieg", "angriff", "terror", "krise", "gewalt",
    "eilmeldung", "breaking", "live"
]

SEUIL_SELECTION = 6

# ============================================================================
# √âTAPE 1 : R√âCUP√âRATION RSS
# ============================================================================

def recuperer_articles_rss():
    """R√©cup√®re les articles de tous les flux RSS"""
    print("=" * 80)
    print("üì° √âTAPE 1/5 : R√âCUP√âRATION DES FLUX RSS")
    print("=" * 80 + "\n")
    
    tous_articles = []
    
    # Contournement SSL si n√©cessaire
    try:
        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
        pass
    else:
        ssl._create_default_https_context = _create_unverified_https_context
    
    for flux in FLUX_RSS:
        print(f"üîç R√©cup√©ration: {flux['nom']}...")
        try:
            feed = feedparser.parse(flux['url'])
            nb_articles = len(feed.entries)
            print(f"   ‚úÖ {nb_articles} articles trouv√©s")
            
            for entry in feed.entries:
                article = {
                    'titre': entry.get('title', ''),
                    'url': entry.get('link', ''),
                    'description': entry.get('description', ''),
                    'source': flux['nom'],
                    'score_base': flux['score_base'],
                    'date': entry.get('published', '')
                }
                tous_articles.append(article)
        except Exception as e:
            print(f"   ‚ùå Erreur: {e}")
    
    print(f"\n‚úÖ Total: {len(tous_articles)} articles collect√©s\n")
    return tous_articles


# ============================================================================
# √âTAPE 2 : SCORING ET S√âLECTION
# ============================================================================

def scorer_article(article):
    """Calcule le score d'un article"""
    score = article['score_base']
    titre_lower = article['titre'].lower()
    
    # Mots-cl√©s positifs (+3 points)
    for mot in MOTS_CLES_POSITIFS:
        if mot in titre_lower:
            score += 3
            break
    
    # Mots-cl√©s n√©gatifs (-5 points)
    for mot in MOTS_CLES_NEGATIFS:
        if mot in titre_lower:
            score -= 5
            break
    
    # Longueur titre (+1 si < 80 caract√®res)
    if len(article['titre']) < 80:
        score += 1
    
    # Pas de breaking news (+2)
    if not any(x in titre_lower for x in ['eilmeldung', 'breaking', 'live']):
        score += 2
    
    return score


def selectionner_meilleur_article(articles):
    """S√©lectionne le meilleur article selon le scoring"""
    print("=" * 80)
    print("üéØ √âTAPE 2/5 : SCORING ET S√âLECTION")
    print("=" * 80 + "\n")
    
    # Scorer tous les articles
    articles_scores = []
    for article in articles:
        score = scorer_article(article)
        if score >= SEUIL_SELECTION:
            articles_scores.append((article, score))
    
    # Trier par score d√©croissant
    articles_scores.sort(key=lambda x: x[1], reverse=True)
    
    if not articles_scores:
        print("‚ùå Aucun article ne d√©passe le seuil de s√©lection!")
        return None
    
    # Afficher le top 5
    print("üìä Top 5 articles:\n")
    for i, (article, score) in enumerate(articles_scores[:5], 1):
        print(f"{i}. [{score}/10] {article['titre'][:60]}...")
        print(f"   Source: {article['source']}\n")
    
    meilleur = articles_scores[0][0]
    meilleur_score = articles_scores[0][1]
    
    print(f"‚úÖ Article s√©lectionn√© (score: {meilleur_score}/10):")
    print(f"   {meilleur['titre']}")
    print(f"   {meilleur['url']}\n")
    
    return meilleur


# ============================================================================
# √âTAPE 3 : EXTRACTION CONTENU
# ============================================================================

def extraire_contenu_article(url):
    """Extrait le contenu textuel d'un article web"""
    print("=" * 80)
    print("üì∞ √âTAPE 3/5 : EXTRACTION DU CONTENU")
    print("=" * 80 + "\n")
    
    print(f"üîç Extraction depuis: {url[:50]}...\n")
    
    try:
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, verify=False, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        paragraphes = soup.find_all('p')
        texte_complet = []
        
        for p in paragraphes:
            texte = p.get_text().strip()
            if len(texte) > 30:
                texte_complet.append(texte)
        
        contenu = '\n\n'.join(texte_complet)
        contenu = contenu[:2000]
        
        print(f"‚úÖ Contenu extrait: {len(contenu)} caract√®res\n")
        return contenu
    
    except Exception as e:
        print(f"‚ùå Erreur extraction: {e}\n")
        return None


# ============================================================================
# √âTAPE 4 : G√âN√âRATION LLM
# ============================================================================

def generer_section_llm(texte, titre, section_type, model="phi3"):
    """G√©n√®re une section avec Ollama"""
    
    prompts = {
        "article": f"""Simplifie ce texte allemand au niveau A2.

R√àGLES STRICTES:
- Exactement 10-12 phrases
- Chaque phrase: 6-10 mots maximum
- Pr√©sent uniquement
- Vocabulaire A2 basique
- PAS de noms propres compliqu√©s

Texte: {texte[:1200]}

√âcris SEULEMENT le texte allemand simplifi√© (arr√™te apr√®s 12 phrases):""",

        "vocabulaire": f"""Extrait 5 mots allemands UTILES de ce texte (pas de noms propres).

Texte: {texte[:1000]}

Format EXACT (une ligne par mot):
1. [mot allemand] = [traduction fran√ßaise]
2. [mot allemand] = [traduction fran√ßaise]
3. [mot allemand] = [traduction fran√ßaise]
4. [mot allemand] = [traduction fran√ßaise]
5. [mot allemand] = [traduction fran√ßaise]

Choisis des VERBES, NOMS ou ADJECTIFS utiles.
√âcris UNIQUEMENT les 5 lignes:""",

        "grammaire": f"""Trouve UNE r√®gle de grammaire allemande simple dans ce texte.

Texte: {texte[:800]}

Explique en fran√ßais en 2-3 phrases courtes et claires.
Donne un exemple simple.
√âcris UNIQUEMENT l'explication en fran√ßais:""",

        "resume": f"""R√©sume ce texte en fran√ßais en 3 phrases courtes (40-60 mots total).

Texte: {texte[:1000]}

√âcris UNIQUEMENT le r√©sum√© fran√ßais (3 phrases):"""
    }
    
    prompt = prompts.get(section_type, "")
    
    try:
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": model,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,
                    "num_predict": 250 if section_type == "article" else 120
                }
            },
            timeout=90
        )
        
        if response.status_code == 200:
            result = response.json()
            generated = result.get('response', '').strip()
            
            # Nettoyage
            if section_type == "article" and len(generated) > 650:
                generated = generated[:650].rsplit('.', 1)[0] + '.'
            
            return generated
        else:
            return None
            
    except Exception as e:
        print(f"   ‚ö†Ô∏è Erreur LLM: {e}")
        return None


def generer_newsletter_llm(contenu, titre):
    """G√©n√®re toutes les sections de la newsletter"""
    print("=" * 80)
    print("ü§ñ √âTAPE 4/5 : G√âN√âRATION AVEC LLM (PHI-3)")
    print("=" * 80 + "\n")
    
    sections = {}
    
    # Article
    print("   üìù 1/4 - Article simplifi√© (30-60s)...")
    sections['article'] = generer_section_llm(contenu, titre, "article")
    if sections['article']:
        print(f"   ‚úÖ G√©n√©r√©: {len(sections['article'])} caract√®res")
    else:
        print("   ‚ùå √âchec")
        return None
    
    # Vocabulaire
    print("\n   üìö 2/4 - Vocabulaire (20-40s)...")
    sections['vocabulaire'] = generer_section_llm(contenu, titre, "vocabulaire")
    if sections['vocabulaire']:
        nb_mots = len([l for l in sections['vocabulaire'].split('\n') if '=' in l])
        print(f"   ‚úÖ G√©n√©r√©: {nb_mots} mots")
    else:
        print("   ‚ùå √âchec")
        return None
    
    # Grammaire
    print("\n   üìñ 3/4 - Point de langue (20-40s)...")
    sections['grammaire'] = generer_section_llm(contenu, titre, "grammaire")
    if sections['grammaire']:
        print(f"   ‚úÖ G√©n√©r√©: {len(sections['grammaire'])} caract√®res")
    else:
        print("   ‚ùå √âchec")
        return None
    
    # R√©sum√©
    print("\n   üá´üá∑ 4/4 - R√©sum√© fran√ßais (20-40s)...")
    sections['resume'] = generer_section_llm(contenu, titre, "resume")
    if sections['resume']:
        print(f"   ‚úÖ G√©n√©r√©: {len(sections['resume'].split())} mots")
    else:
        print("   ‚ùå √âchec")
        return None
    
    print()
    return sections


# ============================================================================
# √âTAPE 5 : G√âN√âRATION HTML
# ============================================================================

def generer_html(titre, sections, url_source, template_path="newsletter_template.html"):
    """G√©n√®re le HTML final"""
    print("=" * 80)
    print("üé® √âTAPE 5/5 : G√âN√âRATION HTML")
    print("=" * 80 + "\n")
    
    # Charger template
    print("üìÑ Chargement du template...")
    try:
        with open(template_path, 'r', encoding='utf-8') as f:
            template = f.read()
        print("   ‚úÖ Template charg√©\n")
    except FileNotFoundError:
        print(f"   ‚ùå Template non trouv√©: {template_path}\n")
        return None
    
    # Parser vocabulaire
    vocab_html = ""
    for ligne in sections['vocabulaire'].split('\n'):
        if '=' in ligne:
            parts = ligne.split('=', 1)
            if len(parts) == 2:
                mot = re.sub(r'^\d+\.\s*', '', parts[0]).strip()
                trad = parts[1].strip()
                vocab_html += f"""
                    <li class="vocab-item">
                        <div class="vocab-word">{mot}</div>
                        <div class="vocab-translation">= {trad}</div>
                    </li>"""
    
    # Remplacer placeholders
    print("üîß Assemblage du HTML...")
    html = template
    replacements = {
        '{{TITRE_ARTICLE}}': titre,
        '{{ARTICLE_SIMPLIFIE}}': sections['article'].replace('\n', '<br><br>'),
        '{{VOCABULAIRE_ITEMS}}': vocab_html,
        '{{POINT_LANGUE}}': sections['grammaire'].replace('\n', '<br><br>'),
        '{{RESUME_FRANCAIS}}': sections['resume'].replace('\n', '<br><br>'),
        '{{DATE}}': datetime.now().strftime("%d/%m/%Y"),
        '{{LIEN_ARTICLE}}': url_source
    }
    
    for placeholder, value in replacements.items():
        html = html.replace(placeholder, value)
    
    print("   ‚úÖ HTML assembl√©\n")
    
    # Sauvegarder
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    html_filename = f"newsletter_{timestamp}.html"
    
    print(f"üíæ Sauvegarde: {html_filename}")
    try:
        with open(html_filename, 'w', encoding='utf-8') as f:
            f.write(html)
        print(f"   ‚úÖ Fichier cr√©√©!\n")
        return html_filename
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}\n")
        return None


# ============================================================================
# SAUVEGARDE JSON
# ============================================================================

def sauvegarder_json(titre, sections, url_source):
    """Sauvegarde les donn√©es en JSON"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    contenu_newsletter = f"""üì∞ {titre}

=== ARTICLE SIMPLIFI√â (Niveau A2) ===
{sections['article']}

=== VOCABULAIRE UTILE ===
{sections['vocabulaire']}

=== POINT DE LANGUE ===
{sections['grammaire']}

=== R√âSUM√â EN FRAN√áAIS ===
{sections['resume']}"""
    
    data = {
        "date_generation": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "titre_original": titre,
        "url_source": url_source,
        "contenu_newsletter": contenu_newsletter,
        "modele_llm": "ollama-phi3-pipeline",
        "statut": "succ√®s"
    }
    
    filename = f"newsletter_{timestamp}.json"
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"üíæ JSON sauvegard√©: {filename}")
    except Exception as e:
        print(f"‚ö†Ô∏è  Erreur JSON: {e}")


# ============================================================================
# PIPELINE PRINCIPAL
# ============================================================================

def main():
    """Ex√©cute le pipeline complet"""
    print("\n" + "=" * 80)
    print("üöÄ NEWSLETTER GENERATOR - PIPELINE COMPLET")
    print("=" * 80 + "\n")
    
    debut = datetime.now()
    
    # √âtape 1: RSS
    articles = recuperer_articles_rss()
    if not articles:
        print("‚ùå Aucun article r√©cup√©r√©. Arr√™t.")
        return
    
    # √âtape 2: S√©lection
    article = selectionner_meilleur_article(articles)
    if not article:
        print("‚ùå Aucun article s√©lectionn√©. Arr√™t.")
        return
    
    # √âtape 3: Extraction
    contenu = extraire_contenu_article(article['url'])
    if not contenu:
        print("‚ùå Impossible d'extraire le contenu. Arr√™t.")
        return
    
    # √âtape 4: LLM
    sections = generer_newsletter_llm(contenu, article['titre'])
    if not sections:
        print("‚ùå √âchec de la g√©n√©ration LLM. Arr√™t.")
        return
    
    # √âtape 5: HTML
    html_file = generer_html(article['titre'], sections, article['url'])
    if not html_file:
        print("‚ùå √âchec de la g√©n√©ration HTML. Arr√™t.")
        return
    
    # Sauvegarde JSON
    sauvegarder_json(article['titre'], sections, article['url'])
    
    # R√©sum√© final
    duree = (datetime.now() - debut).total_seconds()
    
    print("\n" + "=" * 80)
    print("‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS!")
    print("=" * 80)
    print(f"\nüìß Newsletter g√©n√©r√©e: {html_file}")
    print(f"‚è±Ô∏è  Temps total: {int(duree // 60)}m {int(duree % 60)}s")
    print(f"\nüí° Ouvrez {html_file} dans votre navigateur pour pr√©visualiser!")
    print("\nüéØ Prochaine √©tape: Envoi automatique par email (Brevo)\n")


if __name__ == "__main__":
    main()
